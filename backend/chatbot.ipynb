{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a72ce3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tanus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import websockets\n",
    "import redis\n",
    "import os\n",
    "\n",
    "\n",
    "# LangChain, FAISS, and text splitter imports\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings  # Using this as a placeholder for Gemini embedding.\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "# Google Generative AI (Gemini) import\n",
    "import google.generativeai as genai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41ad7e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a09b3e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure your API key for Gemini\n",
    "os.environ['GOOGLE_API_KEY'] = \"AIzaSyCPjR5u_-p8mqcjyujpLazP7TTwkr521eY\"  # Replace with your actual API key.\n",
    "genai.configure(api_key=os.environ['GOOGLE_API_KEY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62a9b05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to Redis (adjust host/port if needed)\n",
    "redis_client = redis.Redis(host='localhost', port=6379, db=0)\n",
    "\n",
    "def fetch_f1_data():\n",
    "    # Try Redis first\n",
    "    data = redis_client.get(\"f1:current\")\n",
    "\n",
    "    if data:\n",
    "        print(\"Fetched data from Redis\")\n",
    "        return data\n",
    "\n",
    "    # If Redis has no data, fallback to external API\n",
    "    try:\n",
    "        response = requests.get(\"https://f1connectapi.vercel.app/api/current/fp1?limit=5\")\n",
    "        if response.status_code == 200:\n",
    "            data = response.text\n",
    "            redis_client.set(\"f1:current\", data, ex=300)  # cache for 5 min\n",
    "            print(\"Fetched data from API and cached in Redis\")\n",
    "            return data\n",
    "        else:\n",
    "            print(\"API error:\", response.status_code)\n",
    "            return \"Error fetching F1 data.\"\n",
    "    except Exception as e:\n",
    "        print(\"Exception while calling API:\", e)\n",
    "        return \"API call failed.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a04ac8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_with_langchain(data):\n",
    "    \"\"\"\n",
    "    Use LangChain’s RecursiveCharacterTextSplitter to divide the raw F1 data\n",
    "    into manageable chunks for later embedding.\n",
    "    \"\"\"\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "    chunks = splitter.split_text(data)\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54ed48a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_embeddings_in_faiss(chunks):\n",
    "    \"\"\"\n",
    "    Create a FAISS index from text chunks. We use HuggingFaceEmbeddings here as a placeholder.\n",
    "    In your actual implementation, replace this with a Gemini 2.0 Flash embedding call if available.\n",
    "    \"\"\"\n",
    "    # Instantiate an embeddings model (placeholder—replace if you have a Gemini embedding API)\n",
    "    hf_embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    \n",
    "    # Build the FAISS vector store from the chunks\n",
    "    vector_store = FAISS.from_texts(chunks, hf_embeddings)\n",
    "    \n",
    "    # Optionally, save the index locally for reuse\n",
    "    vector_store.save_local(\"faiss_index\")\n",
    "    return vector_store\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a78911dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_rag(vector_store, question):\n",
    "    \"\"\"\n",
    "    Given a user query, perform a similarity search on the FAISS index and use the Gemini model to generate an answer.\n",
    "    \"\"\"\n",
    "    # Retrieve top 3 most relevant document chunks\n",
    "    retrieved_docs = vector_store.similarity_search(question, k=3)\n",
    "    \n",
    "    # Combine the retrieved documents’ content into a single context string\n",
    "    context = \"\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "    \n",
    "    # Build a structured prompt\n",
    "    prompt = (\n",
    "        \"Answer this F1-related question in one or two sentences. Use only the context provided.\\n\\n\"\n",
    "        f\"Context: {context}\\n\\n\"\n",
    "        f\"Question: {question}\\n\\n\"\n",
    "        \"Answer:\"\n",
    "    )\n",
    "    \n",
    "    # Use Gemini 2.0 Flash generative model to generate the response\n",
    "    model = genai.GenerativeModel(\"gemini-2.0-flash\")\n",
    "    response = model.generate_content(prompt)\n",
    "    \n",
    "    if response.text:\n",
    "        return response.text.strip()\n",
    "    else:\n",
    "        return \"I'm sorry, I could not generate an answer at this time.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceabac81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WebSocket server started on ws://localhost:5000\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 10048] error while attempting to bind on address ('127.0.0.1', 5000): [winerror 10048] only one usage of each socket address (protocol/network address/port) is normally permitted",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 46\u001b[39m\n\u001b[32m     43\u001b[39m     asyncio.get_event_loop().run_forever()\n\u001b[32m     45\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     \u001b[43mrun_websocket_server\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 42\u001b[39m, in \u001b[36mrun_websocket_server\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     40\u001b[39m server = websockets.serve(handler, \u001b[33m\"\u001b[39m\u001b[33mlocalhost\u001b[39m\u001b[33m\"\u001b[39m,\u001b[32m5000\u001b[39m)\n\u001b[32m     41\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mWebSocket server started on ws://localhost:5000\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m \u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_event_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m asyncio.get_event_loop().run_forever()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\nest_asyncio.py:98\u001b[39m, in \u001b[36m_patch_loop.<locals>.run_until_complete\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f.done():\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     97\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mEvent loop stopped before Future completed.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tanus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\futures.py:203\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception.with_traceback(\u001b[38;5;28mself\u001b[39m._exception_tb)\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tanus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\tasks.py:314\u001b[39m, in \u001b[36mTask.__step_run_and_handle_result\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    311\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    312\u001b[39m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[32m    313\u001b[39m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m314\u001b[39m         result = \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    315\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    316\u001b[39m         result = coro.throw(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tanus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\tasks.py:684\u001b[39m, in \u001b[36mensure_future.<locals>._wrap_awaitable\u001b[39m\u001b[34m(awaitable)\u001b[39m\n\u001b[32m    683\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_wrap_awaitable\u001b[39m(awaitable):\n\u001b[32m--> \u001b[39m\u001b[32m684\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m awaitable\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tanus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\websockets\\legacy\\server.py:1131\u001b[39m, in \u001b[36mServe.__await_impl__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1130\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__await_impl__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> WebSocketServer:\n\u001b[32m-> \u001b[39m\u001b[32m1131\u001b[39m     server = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m._create_server()\n\u001b[32m   1132\u001b[39m     \u001b[38;5;28mself\u001b[39m.ws_server.wrap(server)\n\u001b[32m   1133\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ws_server\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\tanus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\base_events.py:1571\u001b[39m, in \u001b[36mBaseEventLoop.create_server\u001b[39m\u001b[34m(self, protocol_factory, host, port, family, flags, sock, backlog, ssl, reuse_address, reuse_port, ssl_handshake_timeout, ssl_shutdown_timeout, start_serving)\u001b[39m\n\u001b[32m   1569\u001b[39m                 logger.warning(msg)\n\u001b[32m   1570\u001b[39m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1571\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(err.errno, msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1573\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sockets:\n\u001b[32m   1574\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mcould not bind on any address out of \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m   1575\u001b[39m                   % ([info[\u001b[32m4\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m info \u001b[38;5;129;01min\u001b[39;00m infos],))\n",
      "\u001b[31mOSError\u001b[39m: [Errno 10048] error while attempting to bind on address ('127.0.0.1', 5000): [winerror 10048] only one usage of each socket address (protocol/network address/port) is normally permitted"
     ]
    }
   ],
   "source": [
    "async def handler(websocket, path):\n",
    "    \"\"\"\n",
    "    WebSocket handler that:\n",
    "      1. Receives a query from the client.\n",
    "      2. Fetches the latest F1 data from Redis.\n",
    "      3. Processes the data into chunks.\n",
    "      4. Builds/updates the FAISS index.\n",
    "      5. Retrieves context and generates an answer.\n",
    "      6. Sends the answer back to the client.\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        try:\n",
    "            # Step 6.1: Receive a user query via WebSocket\n",
    "            user_query = await websocket.recv()\n",
    "            print(f\"Received query: {user_query}\")\n",
    "\n",
    "            # Step 6.2: Fetch current F1 data from Redis\n",
    "            f1_data = fetch_f1_data()\n",
    "            \n",
    "            # Step 6.3: Process data into text chunks\n",
    "            chunks = process_data_with_langchain(f1_data)\n",
    "            \n",
    "            # Step 6.4: Build a FAISS vector store from these chunks\n",
    "            vector_store = store_embeddings_in_faiss(chunks)\n",
    "            \n",
    "            # Step 6.5: Query the RAG retriever and generate an answer\n",
    "            answer = query_rag(vector_store, user_query)\n",
    "            print(f\"Generated answer: {answer}\")\n",
    "            \n",
    "            # Step 6.6: Send the answer back via WebSocket\n",
    "            await websocket.send(answer)\n",
    "        except websockets.ConnectionClosed:\n",
    "            print(\"Connection closed by client\")\n",
    "            break\n",
    "\n",
    "def run_websocket_server():\n",
    "    \"\"\"\n",
    "    Start the WebSocket server on localhost, port 5050.\n",
    "    \"\"\"\n",
    "    server = websockets.serve(handler, \"localhost\",5050)\n",
    "    print(\"WebSocket server started on ws://localhost:5050\")\n",
    "    asyncio.get_event_loop().run_until_complete(server)\n",
    "    asyncio.get_event_loop().run_forever()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_websocket_server()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "83fbfcce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exception while calling API: name 'requests' is not defined\n",
      "API call failed.\n"
     ]
    }
   ],
   "source": [
    "data = fetch_f1_data()\n",
    "print(data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
